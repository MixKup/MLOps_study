1. Создать новый backet в Yandex Cloud Object Storage и скопировать
в него содержимое предоставленного Вам хранилища с использованием инструмента s3cmd. Для проверки преподавателем данный basket необходимо
сделать общедоступным, а точку доступа к нему привести в README-файле
Вашего GitHub-репозитория.
исходник:
`s3://mlops-data/fraud-data/`
2. Создать Spark-кластер в Data Proc с двумя подкластерами со следующими характеристиками:
- Мастер-подкластер: класс хоста s3-c2-m8, размер хранилища 40 ГБ.
- Data-подкластер: класс хоста s3-c4-m16, 3 хоста, размер хранилища
128 ГБ.
3. Соединиться по SSH с мастер-узлом и выполнить на нём команду копирования содержимого хранилища в файловую систему HDFS с использованием инструмента hadoop distcp. Для проверки преподавателем необходимо
вывести содержимое HDFS-директории в консоль, а снимок экрана с этой информацией привести в README-файле Вашего GitHub-репозитория.
4. Пользуясь тарифным калькулятором Yandex Cloud, оценить месячные
затраты для поддержания работоспособности созданного кластера. Оценить,
насколько использование HDFS-хранилища дороже, чем объектного.
Указание. Кроме тарифного калькулятора, позволяющего делать оценку требуемых средств, на странице платежного аккаунта есть раздел с детализацией биллинга за произвольный период времени. С его помощью можно определить сумму уже потраченных средств на каждый из используемых облачных
сервисов в процессе работы.
5. Предложить способы для оптимизации затрат на содержание Sparkкластера в облаке и попробовать их реализовать.
6. В соответствии с достигнутыми результатами, изменить статус ранее
созданных задач на Kanban-доске в GitHub Projects. Возможно, некоторые
задачи нужно будет скорректировать, разделить на подзадачи или объединить друг с другом.
7. Полностью удалить созданный кластер, чтобы избежать оплаты ресурсов в период его простаивания.
